{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import foam_ct_phantom\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pylab as pl\n",
    "from scipy.optimize import minimize\n",
    "import tomopy\n",
    "import msdnet\n",
    "import glob\n",
    "pl.gray()\n",
    "\n",
    "# configuration parameters\n",
    "random_seed = 3141519\n",
    "phantom_path = Path('phantom.h5') # stores phantom object path\n",
    "phantom_par_path = Path('projs_par.h5') # stores phantom parameters path\n",
    "phantom_vol_path = Path('phantom_volume.h5') # generated phantom volume path\n",
    "phantom_projs_path = Path('phantom_projs.h5')  # simulated projections through phantom path\n",
    "size = 256  # image size for projections\n",
    "max_shift = 16  # max amount of shifting (we'll need this extra area for cropping)\n",
    "sim_size = size + 2*max_shift\n",
    "pixel_size = 3/size\n",
    "#thetas = np.linspace(0, np.pi, 128, False)\n",
    "thetas = np.linspace(np.deg2rad(30), np.deg2rad(150), 128, False)\n",
    "# shift variables\n",
    "random_shift_size = 10 # shift up to this many pixels in x and y\n",
    "center_offset_shift = 6 # center offset amount\n",
    "random_walk_size = 0.5 # shift up to this many pixels in x and y, cumulative per projection\n",
    "# msdnet parameters\n",
    "msdnet_root = Path('msdnet')\n",
    "msdnet_fn = 'regr_params.h5'\n",
    "dilation_size = 5 # dilations in network go from [1, dilation_size]\n",
    "num_layers = 50 # number of NN layers\n",
    "n_above_and_below = 2 # how many sinograms to load above and below the active one\n",
    "num_train_datasets = 1#5 # how many tomography datasets to create for training\n",
    "num_validate_datasets = 1 # how many tomography datasets to create for validation\n",
    "gpu=True\n",
    "\n",
    "def generate_shifts(num_projs, random_shift_size, center_offset_shift, random_walk_size, max_shift=None):\n",
    "    # apply random shifts\n",
    "    shifts = np.random.random_sample((num_projs, 2)) # (y,x) order\n",
    "    shifts *= random_shift_size * 2\n",
    "    shifts -= random_shift_size\n",
    "\n",
    "    # apply center offset shifts\n",
    "    shifts[:, 1] += center_offset_shift\n",
    "\n",
    "    # apply random walk shifts\n",
    "    random_walk_shifts = np.random.random_sample((num_projs, 2)) # (y,x) order\n",
    "    random_walk_shifts *= random_walk_size * 2\n",
    "    random_walk_shifts -= random_walk_size\n",
    "    random_walk_shifts = np.cumsum(random_walk_shifts, axis=0)\n",
    "    shifts += random_walk_shifts\n",
    "\n",
    "    # limit overall shift size to max_shift\n",
    "    if max_shift is not None:\n",
    "        np.clip(shifts, -max_shift, max_shift, shifts)\n",
    "    return shifts\n",
    "\n",
    "\n",
    "def create_test_dataset(root_path, thetas, random_shift_size, center_offset_shift, random_walk_size, max_shift, size,\n",
    "                        sim_size, pixel_size, display=False):\n",
    "    root_path.mkdir(parents=True, exist_ok=True)\n",
    "    # create phantom\n",
    "    phantom_path = root_path / \"phantom.h5\"\n",
    "    if not phantom_path.exists():\n",
    "        # Note that nspheres_per_unit is set to a low value to reduce the computation time here.\n",
    "        # The default value is 100000.\n",
    "        foam_ct_phantom.FoamPhantom.generate(str(phantom_path), np.random.random_sample(), nspheres_per_unit=1000)\n",
    "    phantom = foam_ct_phantom.FoamPhantom(str(phantom_path))\n",
    "\n",
    "    # create phantom volume\n",
    "    phantom_path = root_path / \"phantom_volume.h5\"\n",
    "    geom = foam_ct_phantom.VolumeGeometry(sim_size, sim_size, sim_size, pixel_size)\n",
    "    if not phantom_vol_path.exists():\n",
    "        phantom.generate_volume(str(phantom_vol_path), geom)\n",
    "    vol = foam_ct_phantom.load_volume(str(phantom_vol_path))\n",
    "    if display:\n",
    "        pl.imshow(vol[vol.shape[0]//2])\n",
    "        pl.show()\n",
    "\n",
    "    # create projections\n",
    "    proj_geom = foam_ct_phantom.ParallelGeometry(sim_size, sim_size, thetas, pixel_size)\n",
    "    if not phantom_projs_path.exists():\n",
    "        phantom.generate_projections(str(phantom_projs_path), proj_geom)\n",
    "    projs = foam_ct_phantom.load_projections(str(phantom_projs_path))\n",
    "    if display:\n",
    "        pl.imshow(projs[projs.shape[0]//2])\n",
    "        pl.show()\n",
    "\n",
    "    # Reconstruct with no shifts applied\n",
    "    if display:\n",
    "        rec = tomopy.recon(projs, thetas, algorithm=\"sirt\", num_iter=30)\n",
    "        pl.imshow(rec[rec.shape[0]//2])\n",
    "        pl.show()\n",
    "\n",
    "    # create shifts for projections\n",
    "    shifts = generate_shifts(projs.shape[0], random_shift_size, center_offset_shift, random_walk_size, max_shift)\n",
    "    if display:\n",
    "        pl.plot(np.rad2deg(thetas), shifts[:, 1], label=\"x-shifts\")\n",
    "        pl.plot(np.rad2deg(thetas), shifts[:, 0], label=\"y-shifts\")\n",
    "        pl.xlabel(\"deg\")\n",
    "        pl.ylabel(\"shifts\")\n",
    "        pl.legend()\n",
    "        pl.show()\n",
    "\n",
    "    # shift projections and then crop using max_shift (shift in projection space)\n",
    "    tomopy.exp_minus(projs, out=projs)\n",
    "    projs = tomopy.shift_images(projs, shifts[:, 1], shifts[:, 0])\n",
    "    projs = projs[:, max_shift:max_shift+size, max_shift:max_shift+size]\n",
    "    np.clip(projs, 1e-6, 1-1e-6, projs)\n",
    "    tomopy.minus_log(projs, out=projs)\n",
    "\n",
    "    # crop phantom vol to match reconstruction vol\n",
    "    vol = vol[max_shift:max_shift+size, max_shift:max_shift+size, max_shift:max_shift+size]\n",
    "\n",
    "    # Reconstruct with shifts applied\n",
    "    rec = tomopy.recon(projs, thetas, algorithm=\"sirt\", num_iter=1)\n",
    "    if display:\n",
    "        pl.imshow(rec[rec.shape[0]//2])\n",
    "        pl.show()\n",
    "\n",
    "    return vol, rec, projs, shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:51<00:00, 29.34it/s] \n",
      "100%|██████████| 1500/1500 [00:51<00:00, 29.05it/s] \n",
      "  0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of input channels (1280) does not match expected number (5).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-0e51786d8998>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0;31m# Train network until program is stopped manually (or stops improving)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0mstopcrit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmsdnet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstoppingcriterion\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNonImprovingValidationSteps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m     \u001B[0mmsdnet\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbprov\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsdnet_params_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mloggers\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mconsolelog\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mfilelog\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mimagelog\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_every\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalidate_dats\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstopcrit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstopcrit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprogress\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tomopy/lib/python3.6/site-packages/msdnet/train.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(network, trainalg, validation, dataprov, outputfile, val_every, loggers, stopcrit, progress)\u001B[0m\n\u001B[1;32m    185\u001B[0m     \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    186\u001B[0m         \u001B[0mbatch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdataprov\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetbatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 187\u001B[0;31m         \u001B[0mtrainalg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnetwork\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    188\u001B[0m         \u001B[0mntrainimages\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0mnstep\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tomopy/lib/python3.6/site-packages/msdnet/train.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, n, dlist)\u001B[0m\n\u001B[1;32m     82\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdlist\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m             \u001B[0minp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmsk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 84\u001B[0;31m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     85\u001B[0m             \u001B[0merr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mderiv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtar\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mmsk\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tomopy/lib/python3.6/site-packages/msdnet/network.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, im, returnoutput)\u001B[0m\n\u001B[1;32m    189\u001B[0m             \u001B[0mim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mim\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnewaxis\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    190\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m!=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnin\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 191\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Number of input channels ({}) does not match expected number ({}).\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    192\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m!=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mims\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    193\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mims\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataobject\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdl\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Number of input channels (1280) does not match expected number (5)."
     ]
    }
   ],
   "source": [
    "msdnet_root.mkdir(parents=True, exist_ok=True)\n",
    "msdnet_params_path = msdnet_root / msdnet_fn\n",
    "if not msdnet_params_path.exists():\n",
    "    # create and train network\n",
    "    dilations = msdnet.dilations.IncrementDilations(dilation_size)\n",
    "    input_channels = 2 * n_above_and_below + 1\n",
    "    n = msdnet.network.MSDNet(num_layers, dilations, input_channels, 1, gpu=gpu)\n",
    "    # Initialize network parameters\n",
    "    n.initialize()\n",
    "    # create test data\n",
    "    train_dats = []\n",
    "    for i in range(num_train_datasets):\n",
    "        train_path = msdnet_root / f\"train_{i:05}\"\n",
    "        vol, rec, projs, shifts = create_test_dataset(train_path, thetas, random_shift_size, center_offset_shift, random_walk_size, max_shift, size, sim_size, pixel_size, display=False)\n",
    "        # load rec and ground truth (vol) into datasets\n",
    "        dats = []\n",
    "        for j in range(vol.shape[0]):\n",
    "            dats.append(msdnet.data.ArrayDataPoint(rec[j], vol[j]))\n",
    "        # Convert input slices to input slabs (i.e. multiple slices as input)\n",
    "        dats = msdnet.data.convert_to_slabs(dats, n_above_and_below, flip=False)\n",
    "        train_dats.extend(dats)\n",
    "    # Normalize input and output of network to zero mean and unit variance using\n",
    "    # training data images\n",
    "    n.normalizeinout(train_dats)\n",
    "    # Use image batches of a single image\n",
    "    bprov = msdnet.data.BatchProvider(train_dats, 1)\n",
    "    validate_dats = []\n",
    "    for i in range(num_validate_datasets):\n",
    "        validate_path = msdnet_root / f\"validate_{i:05}\"\n",
    "        vol, rec, projs, shifts = create_test_dataset(validate_path, thetas, random_shift_size, center_offset_shift, random_walk_size, max_shift, size, sim_size, pixel_size, display=False)\n",
    "        # load rec and ground truth (vol) into datasets\n",
    "        dats = []\n",
    "        for j in range(vol.shape[0]):\n",
    "            dats.append(msdnet.data.ArrayDataPoint(rec[j], vol[j]))\n",
    "        # Convert input slices to input slabs (i.e. multiple slices as input)\n",
    "        dats = msdnet.data.convert_to_slabs(dats, n_above_and_below, flip=False)\n",
    "        validate_dats.extend(dats)\n",
    "\n",
    "    # Validate with Mean-Squared Error\n",
    "    val = msdnet.validate.MSEValidation(validate_dats)\n",
    "\n",
    "    # Use ADAM training algorithms\n",
    "    t = msdnet.train.AdamAlgorithm(n)\n",
    "\n",
    "    # Log error metrics to console\n",
    "    consolelog = msdnet.loggers.ConsoleLogger()\n",
    "    # Log error metrics to file\n",
    "    filelog = msdnet.loggers.FileLogger(str(msdnet_root/'log_tomo_regr.txt'))\n",
    "    # Log typical, worst, and best images to image files\n",
    "    imagelog = msdnet.loggers.ImageLogger(str(msdnet_root/'log_tomo_regr'), onlyifbetter=True, chan_in=2)\n",
    "\n",
    "    # Train network until program is stopped manually (or stops improving)\n",
    "    stopcrit = msdnet.stoppingcriterion.NonImprovingValidationSteps(5)\n",
    "    msdnet.train.train(n, t, val, bprov, str(msdnet_params_path),loggers=[consolelog,filelog,imagelog], val_every=len(validate_dats), stopcrit=stopcrit, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load network from file\n",
    "n = msdnet.network.MSDNet.from_file(str(msdnet_params_path), gpu=gpu)\n",
    "\n",
    "# create test dataset\n",
    "test_path = msdnet_root / f\"test\"\n",
    "vol, rec, projs, shifts = create_test_dataset(test_path, thetas, random_shift_size, center_offset_shift, random_walk_size, max_shift, size, sim_size, pixel_size, display=True)\n",
    "# load rec and ground truth (vol) into datasets\n",
    "dats = []\n",
    "for j in range(vol.shape[0]):\n",
    "    dats.append(msdnet.data.ArrayDataPoint(rec[j], vol[j]))\n",
    "# Convert input slices to input slabs (i.e. multiple slices as input)\n",
    "dats = msdnet.data.convert_to_slabs(dats, n_above_and_below, flip=False)\n",
    "# run network on reconstruction\n",
    "nn_out = np.zeros_like(rec)\n",
    "for i in range(rec.shape[0]):\n",
    "    nn_out = n.forward(dats[i].input)\n",
    "pl.imshow(nn_out[nn_out.shape[0]//2])\n",
    "pl.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# standard shift correction\n",
    "align_shifts = np.zeros_like(shifts)\n",
    "aligned_projs, align_shifts[:,1], align_shifts[:,0], error = tomopy.align_seq(projs, thetas, iters=10, upsample_factor=100, blur=False, save=True)\n",
    "\n",
    "# plot difference\n",
    "diff_shifts = shifts + align_shifts\n",
    "pl.plot(np.rad2deg(thetas), diff_shifts[:, 1], label=\"x-shifts\")\n",
    "pl.plot(np.rad2deg(thetas), diff_shifts[:, 0], label=\"y-shifts\")\n",
    "pl.xlabel(\"deg\")\n",
    "pl.ylabel(\"Diff in Shifts\")\n",
    "pl.legend()\n",
    "pl.show()\n",
    "\n",
    "# recon after shifts corrected\n",
    "rec = tomopy.recon(aligned_projs, thetas, algorithm=\"sirt\", num_iter=30)\n",
    "\n",
    "pl.imshow(rec[rec.shape[0]//2])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# calculate shift error with x,y,z motion applied\n",
    "# TODO: should we include center shift?\n",
    "def calc_shift_error(thetas, shifts, true_shifts):\n",
    "    # calculate Y-shift that reduces error\n",
    "    options = {'ftol':0.000001}\n",
    "\n",
    "    def _y_cost(args):\n",
    "        y_shift = args\n",
    "        return np.sum(np.square(true_shifts[:,0] - (shifts[:,0] - y_shift)))\n",
    "\n",
    "    res = minimize(_y_cost, (0.0,), method='Powell', options=options)\n",
    "    y_shift = float(res.x)\n",
    "\n",
    "    # now calculate x_shift and z_shift that reduces error in shifts\n",
    "    # z_shift is the sin(theta) and x_shift is the cos(theta)\n",
    "    def _xz_cost(args):\n",
    "        x_shift, z_shift, center_shift = args\n",
    "        new_shifts = shifts[:,1] - (z_shift * np.sin(thetas) + x_shift * np.cos(thetas) + center_shift)\n",
    "        #x_shift, z_shift = args\n",
    "        #new_shifts = shifts[:,1] - (z_shift * np.sin(thetas) + x_shift * np.cos(thetas))\n",
    "        return np.sum(np.square(true_shifts[:,1] - new_shifts))\n",
    "\n",
    "    res = minimize(_xz_cost, (0.0, 0.0, 0.0), method='Powell', options=options)\n",
    "    x_shift, z_shift, center_shift = res.x\n",
    "    #res = minimize(_xz_cost, (0.0, 0.0), method='Powell', options=options)\n",
    "    #center_shift = 0\n",
    "    #x_shift, z_shift, = res.x\n",
    "    new_shifts = shifts.copy()\n",
    "    new_shifts[:,0] -= y_shift\n",
    "    new_shifts[:,1] -= z_shift * np.sin(thetas) + x_shift * np.cos(thetas) + center_shift\n",
    "    error = np.sum(np.square(true_shifts - new_shifts))\n",
    "    return x_shift, y_shift, z_shift, center_shift, error\n",
    "\n",
    "# minimize error in shift output\n",
    "x_shift, y_shift, z_shift, center_shift, error = calc_shift_error(thetas, align_shifts, -shifts)\n",
    "# calc shift error before minimization\n",
    "orig_error = np.sum(np.square(shifts + align_shifts))\n",
    "print(f\"min err: {error}, orig err: {orig_error}, x_shift: {x_shift}, y_shift: {y_shift}, z_shift: {z_shift}, center_shift: {center_shift}\")\n",
    "\n",
    "# calculate aligned shifts with minimized error for display\n",
    "align_shifts_min_err = np.copy(align_shifts)\n",
    "align_shifts_min_err[:, 0] -= y_shift\n",
    "align_shifts_min_err[:, 1] -= z_shift * np.sin(thetas) + x_shift * np.cos(thetas) + center_shift\n",
    "\n",
    "diff_shifts = shifts + align_shifts_min_err\n",
    "pl.plot(np.rad2deg(thetas), diff_shifts[:, 1], label=\"x-shifts\")\n",
    "pl.plot(np.rad2deg(thetas), diff_shifts[:, 0], label=\"y-shifts\")\n",
    "pl.xlabel(\"deg\")\n",
    "pl.ylabel(\"Diff in shifts after minimize\")\n",
    "pl.legend()\n",
    "pl.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}